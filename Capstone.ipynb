{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection as sk\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>AdjOpen</th>\n",
       "      <th>AdjHigh</th>\n",
       "      <th>AdjLow</th>\n",
       "      <th>AdjClose</th>\n",
       "      <th>AdjVol</th>\n",
       "      <th>returns_adj_close</th>\n",
       "      <th>upmove</th>\n",
       "      <th>downmove</th>\n",
       "      <th>...</th>\n",
       "      <th>ma.40</th>\n",
       "      <th>ma.80</th>\n",
       "      <th>macd.10v5</th>\n",
       "      <th>macd.20v10</th>\n",
       "      <th>macd.40v20</th>\n",
       "      <th>macd.80v40</th>\n",
       "      <th>percent.K.5</th>\n",
       "      <th>percent.K.14</th>\n",
       "      <th>percent.K.30</th>\n",
       "      <th>percent.K.60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDB</td>\n",
       "      <td>19960216</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.065677</td>\n",
       "      <td>0.964912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935041</td>\n",
       "      <td>0.936923</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>0.251480</td>\n",
       "      <td>0.409883</td>\n",
       "      <td>0.174791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.215847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDB</td>\n",
       "      <td>19960220</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.090868</td>\n",
       "      <td>1.036364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.935771</td>\n",
       "      <td>0.937246</td>\n",
       "      <td>-0.347682</td>\n",
       "      <td>0.089301</td>\n",
       "      <td>0.321271</td>\n",
       "      <td>0.136999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495049</td>\n",
       "      <td>0.442718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDB</td>\n",
       "      <td>19960606</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.961539</td>\n",
       "      <td>0.090676</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954149</td>\n",
       "      <td>0.933659</td>\n",
       "      <td>-0.096926</td>\n",
       "      <td>-0.101673</td>\n",
       "      <td>-0.271853</td>\n",
       "      <td>-0.730347</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.734992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BANF</td>\n",
       "      <td>19930422</td>\n",
       "      <td>0.875588</td>\n",
       "      <td>0.901725</td>\n",
       "      <td>0.875588</td>\n",
       "      <td>0.901725</td>\n",
       "      <td>0.076594</td>\n",
       "      <td>1.029851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.914304</td>\n",
       "      <td>0.894553</td>\n",
       "      <td>0.078036</td>\n",
       "      <td>0.495841</td>\n",
       "      <td>0.280168</td>\n",
       "      <td>-0.375729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>INDB</td>\n",
       "      <td>19960607</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.091701</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954134</td>\n",
       "      <td>0.934157</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>-0.051579</td>\n",
       "      <td>-0.245460</td>\n",
       "      <td>-0.712054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.681991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker      Date   AdjOpen   AdjHigh    AdjLow  AdjClose    AdjVol  \\\n",
       "0   INDB  19960216  0.916667  0.950000  0.916667  0.916667  0.065677   \n",
       "1   INDB  19960220  0.950000  0.950000  0.916667  0.950000  0.090868   \n",
       "2   INDB  19960606  0.953846  0.969231  0.953846  0.961539  0.090676   \n",
       "3   BANF  19930422  0.875588  0.901725  0.875588  0.901725  0.076594   \n",
       "4   INDB  19960607  0.969231  0.969231  0.953846  0.953846  0.091701   \n",
       "\n",
       "   returns_adj_close  upmove  downmove      ...          ma.40     ma.80  \\\n",
       "0           0.964912     0.0       0.0      ...       0.935041  0.936923   \n",
       "1           1.036364     0.0       0.0      ...       0.935771  0.937246   \n",
       "2           0.992063     0.0       0.0      ...       0.954149  0.933659   \n",
       "3           1.029851     0.0       0.0      ...       0.914304  0.894553   \n",
       "4           0.992000     0.0       0.0      ...       0.954134  0.934157   \n",
       "\n",
       "   macd.10v5  macd.20v10  macd.40v20  macd.80v40  percent.K.5  percent.K.14  \\\n",
       "0   0.019301    0.251480    0.409883    0.174791     0.000000      0.000000   \n",
       "1  -0.347682    0.089301    0.321271    0.136999     1.000000      1.000000   \n",
       "2  -0.096926   -0.101673   -0.271853   -0.730347     0.480769      0.480769   \n",
       "3   0.078036    0.495841    0.280168   -0.375729     1.000000      1.000000   \n",
       "4   0.041618   -0.051579   -0.245460   -0.712054     0.000000      0.000000   \n",
       "\n",
       "   percent.K.30  percent.K.60  \n",
       "0      0.000000      0.215847  \n",
       "1      0.495049      0.442718  \n",
       "2      0.506579      0.734992  \n",
       "3      0.500000      0.500000  \n",
       "4      0.342105      0.681991  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "df=pd.read_csv(\"myeod.csv\")\n",
    "df.replace([np.inf], np.nan)\n",
    "df.dropna(axis=0, how='all')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692842, 37)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_cv_test, Y_train, Y_cv_test = sk.train_test_split(\n",
    "    df.drop([\"Ticker\",\"Date\",\"returns_adj_close\"], axis=1).astype(np.float32),\n",
    "    pd.DataFrame(df[\"returns_adj_close\"].astype(np.float32)),\n",
    "    test_size=0.40,\n",
    "    train_size =0.60,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_cv, X_test, Y_cv, Y_test = sk.train_test_split(\n",
    "    X_cv_test,\n",
    "    Y_cv_test,\n",
    "    test_size=0.50,\n",
    "    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3388128"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[135989 ,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.00005\n",
    "training_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_inputs = 34\n",
    "number_of_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_1_nodes = 300\n",
    "layer_2_nodes = 200\n",
    "layer_3_nodes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "with tf.variable_scope('input'):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, number_of_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer_1'):\n",
    "    weights = tf.get_variable(name = \"weights1\", shape = [number_of_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name = \"biases1\", shape = [layer_1_nodes], initializer = tf.zeros_initializer())\n",
    "    layer_1_output = tf.nn.sigmoid( tf.matmul(X, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer_2'):\n",
    "    weights = tf.get_variable(name = \"weights2\", shape = [layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name = \"biases2\", shape = [layer_2_nodes], initializer = tf.zeros_initializer())\n",
    "    layer_2_output = tf.nn.sigmoid( tf.matmul(layer_1_output, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer_3'):\n",
    "    weights = tf.get_variable(name = \"weights3\", shape = [layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name = \"biases3\", shape = [layer_3_nodes], initializer = tf.zeros_initializer())\n",
    "    layer_3_output = tf.nn.sigmoid( tf.matmul(layer_2_output, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('output'):\n",
    "    weights = tf.get_variable(name = \"weights4\", shape = [layer_3_nodes, number_of_output], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    biases = tf.get_variable(name = \"biases4\", shape = [number_of_output], initializer = tf.zeros_initializer())\n",
    "    output_layer = tf.matmul(layer_3_output, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('cost'):\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "    cost = tf.reduce_mean(tf.squared_difference(output_layer,Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"logging\"):\n",
    "    tf.summary.scalar(\"current_cost\",cost)\n",
    "    summary=tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 nodes:  300\n",
      "Layer 2 nodes:  200\n",
      "Layer 3 nodes:  10\n",
      "\n",
      "============================================================================\n",
      "============================================================================\n",
      "\n",
      "Epoch 0: \t Training Cost: 0.5105771422386169  \t CV Cost: 0.5105352997779846\n",
      "Epoch 5: \t Training Cost: 0.4539581537246704  \t CV Cost: 0.45391884446144104\n",
      "Epoch 10: \t Training Cost: 0.40128934383392334  \t CV Cost: 0.4012509882450104\n",
      "Epoch 15: \t Training Cost: 0.3529181480407715  \t CV Cost: 0.35288000106811523\n",
      "Epoch 20: \t Training Cost: 0.30904144048690796  \t CV Cost: 0.3090059459209442\n",
      "Epoch 25: \t Training Cost: 0.26970869302749634  \t CV Cost: 0.2696716785430908\n",
      "Epoch 30: \t Training Cost: 0.23481318354606628  \t CV Cost: 0.234778493642807\n",
      "Epoch 35: \t Training Cost: 0.20413875579833984  \t CV Cost: 0.20410452783107758\n",
      "Epoch 40: \t Training Cost: 0.17737381160259247  \t CV Cost: 0.17734089493751526\n",
      "Epoch 45: \t Training Cost: 0.154154971241951  \t CV Cost: 0.15412163734436035\n",
      "Epoch 50: \t Training Cost: 0.13409043848514557  \t CV Cost: 0.13405777513980865\n",
      "Epoch 55: \t Training Cost: 0.11679684370756149  \t CV Cost: 0.1167646050453186\n",
      "Epoch 60: \t Training Cost: 0.10190767794847488  \t CV Cost: 0.10187572985887527\n",
      "Epoch 65: \t Training Cost: 0.08908921480178833  \t CV Cost: 0.08905796706676483\n",
      "Epoch 70: \t Training Cost: 0.07804617285728455  \t CV Cost: 0.07801502197980881\n",
      "Epoch 75: \t Training Cost: 0.06851878017187119  \t CV Cost: 0.06848792731761932\n",
      "Epoch 80: \t Training Cost: 0.06028392165899277  \t CV Cost: 0.06025341525673866\n",
      "Epoch 85: \t Training Cost: 0.05315161123871803  \t CV Cost: 0.05312151461839676\n",
      "Epoch 90: \t Training Cost: 0.04695956036448479  \t CV Cost: 0.04692988097667694\n",
      "Epoch 95: \t Training Cost: 0.04157126694917679  \t CV Cost: 0.04154183343052864\n",
      "Epoch 100: \t Training Cost: 0.03687087073922157  \t CV Cost: 0.03684176132082939\n",
      "Epoch 105: \t Training Cost: 0.032760996371507645  \t CV Cost: 0.032732248306274414\n",
      "Epoch 110: \t Training Cost: 0.029159190133213997  \t CV Cost: 0.029130620881915092\n",
      "Epoch 115: \t Training Cost: 0.025995483621954918  \t CV Cost: 0.025967100635170937\n",
      "Epoch 120: \t Training Cost: 0.023210499435663223  \t CV Cost: 0.023182520642876625\n",
      "Epoch 125: \t Training Cost: 0.020754223689436913  \t CV Cost: 0.020726539194583893\n",
      "Epoch 130: \t Training Cost: 0.018583718687295914  \t CV Cost: 0.01855628192424774\n",
      "Epoch 135: \t Training Cost: 0.016662299633026123  \t CV Cost: 0.016635125502943993\n",
      "Epoch 140: \t Training Cost: 0.0149585772305727  \t CV Cost: 0.014931616373360157\n",
      "Epoch 145: \t Training Cost: 0.013445544987916946  \t CV Cost: 0.01341879740357399\n",
      "\n",
      "============================================================================\n",
      "============================================================================\n",
      "\n",
      "Final Training cost:\t 0.012356716208159924\n",
      "Final CV cost      :\t 0.012330109253525734\n",
      "Final Testing cost :\t 0.01231437548995018\n"
     ]
    }
   ],
   "source": [
    "print (\"Layer 1 nodes: \", layer_1_nodes)\n",
    "print (\"Layer 2 nodes: \", layer_2_nodes)\n",
    "print (\"Layer 3 nodes: \", layer_3_nodes)\n",
    "\n",
    "print(\"\\n============================================================================\\n============================================================================\\n\")\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "\n",
    "    # Run the global variable initializer to initialize all variables and layers of the neural network\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create log file writers to record training progress.\n",
    "    # We'll store training and testing log data separately.\n",
    "    training_writer = tf.summary.FileWriter('./logs/200/training-'+str(layer_1_nodes)+'-'+str(layer_2_nodes)+'-'+str(layer_3_nodes), session.graph)\n",
    "    cv_writer = tf.summary.FileWriter('./logs/200/cv-'+str(layer_1_nodes)+'-'+str(layer_2_nodes)+'-'+str(layer_3_nodes), session.graph)\n",
    "\n",
    "    # Run the optimizer over and over to train the network.\n",
    "    # One epoch is one full run through the training data set.\n",
    "    for epoch in range(training_epochs):\n",
    "\n",
    "        # Feed in the training data and do one step of neural network training\n",
    "        session.run(optimizer, feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "        # Every 5 training steps, log our progress\n",
    "        if epoch % 5 == 0:\n",
    "            # Get the current accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "            training_cost, training_summary = session.run([cost, summary], feed_dict={X: X_train, Y:Y_train})\n",
    "            cv_cost, cv_summary = session.run([cost, summary], feed_dict={X: X_cv, Y: Y_cv})\n",
    "\n",
    "            # Write the current training status to the log files (Which we can view with TensorBoard)\n",
    "            training_writer.add_summary(training_summary, epoch)\n",
    "            cv_writer.add_summary(cv_summary, epoch)\n",
    "\n",
    "            # Print the current training status to the screen\n",
    "            print(\"Epoch {}: \\t Training Cost: {}  \\t CV Cost: {}\".format(epoch,training_cost,cv_cost))\n",
    "\n",
    "    # Training is now complete!\n",
    "\n",
    "    # Get the final accuracy scores by running the \"cost\" operation on the training and test data sets\n",
    "    final_training_cost = session.run(cost, feed_dict={X: X_train, Y: Y_train})\n",
    "    final_cv_cost = session.run(cost, feed_dict={X: X_cv, Y: Y_cv})\n",
    "    final_testing_cost=session.run(cost, feed_dict={X: X_test, Y: Y_test})\n",
    "    print(\"\\n============================================================================\\n============================================================================\\n\")\n",
    "    print(\"Final Training cost:\\t {}\".format(final_training_cost))\n",
    "    print(\"Final CV cost      :\\t {}\".format(final_cv_cost))\n",
    "    print(\"Final Testing cost :\\t {}\".format(final_testing_cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
